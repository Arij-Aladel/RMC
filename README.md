1. [Neural Machine Reading Comprehension:Methods and Trends](https://arxiv.org/pdf/1907.01118v1.pdf)

2. [QANET:   COMBININGLOCALCONVOLUTION   WITHGLOBALSELF-ATTENTION   FORREADINGCOMPRE-HENSION](https://arxiv.org/pdf/1804.09541.pdf)

3. [A Survey on Machine Reading Comprehension:Tasks, Evaluation Metrics, and Benchmark Datasets](https://arxiv.org/pdf/2006.11880v1.pdf)
4. [NEURAL READING COMPREHENSION AND BEYOND](https://www.cs.princeton.edu/~danqic/papers/thesis.pdf)
5. [CoQA: A Conversational Question Answering Challenge](https://arxiv.org/pdf/1808.07042.pdf)
6. [BERT with History Answer Embedding for ConversationalQuestion Answering](https://arxiv.org/pdf/1905.05412.pdf)
7. [Conversational Machine Comprehension: a Literature Review](https://arxiv.org/pdf/2006.00671.pdf)
8. [Attentive History Selection for ConversationalQuestion Answering](https://dl.acm.org/doi/pdf/10.1145/3357384.3357905)
9. [FLOWQA: GRASPINGFLOW INHISTORY FORCONVERSATIONALMACHINECOMPREHENSION](https://arxiv.org/pdf/1810.06683.pdf)  ,  [   on git](https://github.com/momohuang/FlowQA)

10. [A Simple but Effective Method to Incorporate Multi-turn Contextwith BERT for Conversational Machine Comprehension](https://arxiv.org/pdf/1905.12848.pdf)
11. [TT-Net: Topic Transfer-Based Neural Network forConversational Reading Comprehension](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8805064&tag=1)
12. [Review Conversational Reading Comprehension](https://arxiv.org/pdf/1902.00821.pdf)

