1. [Analysis of Factoid Questions for Effective Relation ](https://dl.acm.org/doi/pdf/10.1145/1076034.1076131)   August 2005
2. [FastQA: A Simple and Efficient Neural Architecture for Question](https://arxiv.org/pdf/1703.04816v1.pdf), 14 Mar 2017
4. [Reading Wikipedia to Answer Open-Domain Questions](https://arxiv.org/pdf/1704.00051.pdf)  28 April, 2017  [git repo](https://github.com/facebookresearch/DrQA)
5. [Denoising Distantly Supervised Open-Domain Question Answering](https://www.aclweb.org/anthology/P18-1161.pdf) [git](https://github.com/thunlp/OpenQA)
6. [QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension](https://arxiv.org/pdf/1804.09541.pdf), 23 Apr 2018
7. [Stochastic Answer Networks for Machine Reading Comprehension](https://arxiv.org/pdf/1712.03556.pdf),  15 May 2018
8. [NEURAL READING COMPREHENSION AND BEYOND](https://www.cs.princeton.edu/~danqic/papers/thesis.pdf) thesis 2018
9. [A Knowledge-Grounded Neural Conversation Model](https://arxiv.org/pdf/1702.01932.pdf), 15 Nov 2018
10. [Question Answering with BERT and AnswerVerification](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/reports/default/15763476.pdf)  2019
11. [Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations](https://www.isca-speech.org/archive/Interspeech_2019/pdfs/3079.pdf)
12. [SDNET:  CONTEXTUALIZEDATTENTION-BASED DEEP NETWORK   FOR CONVERSATIONAL QUESTIONAN-SWERING](https://arxiv.org/pdf/1812.03593.pdf).  2 Jan 2019
13. [Learning to Transform, Combine, and Reasonin Open-Domain Question Answering](https://dl.acm.org/doi/pdf/10.1145/3289600.3291012)  February 11â€“15, 2019
14. [Question Answering on SQuAD with BERT](Question Answering on SQuAD with BERT) 2019-03-28
15. [CoQA: A Conversational Question Answering Challenge](https://arxiv.org/pdf/1808.07042.pdf), 29 Mar 2019
16. [FLOWQA: GRASPINGFLOW INHISTORY FORCONVERSATIONALMACHINECOMPREHENSION](https://arxiv.org/pdf/1810.06683.pdf) , 16 Apr 2019 ,  [   on git](https://github.com/momohuang/FlowQA)
17. [CS224n Final Project: SQuAD 2.0 with BERT](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/reports/default/15791990.pdf)
18. [A Simple but Effective Method to Incorporate Multi-turn Contextwith BERT for Conversational Machine Comprehension](https://arxiv.org/pdf/1905.12848.pdf) 30 May 2019
19. [Conversing by Reading:Contentful Neural Conversation with On-demand Machine Reading](https://arxiv.org/pdf/1906.02738.pdf), 7 Jun 2019
20. [Multiple Attention Networks with Temporal Convolution for Machine Reading Comprehension](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8784662)12-14 Agust 2019
21. [Neural Machine Reading Comprehension:Methods and Trends](https://arxiv.org/pdf/1907.01118v1.pdf), 2 Jul 2019
22. [Attentive History Selection for ConversationalQuestion Answering](https://dl.acm.org/doi/pdf/10.1145/3357384.3357905) 26 Aug 2019
23. [TT-Net: Topic Transfer-Based Neural Network forConversational Reading Comprehension](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8805064), September 3, 2019.
24. [Neural Approaches to Conversational AI](https://arxiv.org/pdf/1809.08267.pdf), 10 Sep 2019
25. [Multi-passage BERT: A Globally Normalized BERT Model forOpen-domain Question Answering](https://arxiv.org/pdf/1908.08167.pdf), 2 Oct 2019
26. [BERT with History Answer Embedding for ConversationalQuestion Answering](https://arxiv.org/pdf/1905.05412.pdf) 27 Oct 2019
27. [How to Pre-Train Your Model?Comparison of Different Pre-Training Models for Biomedical Question Answering](https://arxiv.org/pdf/1911.00712.pdf) 2 Nov 2019
28. [Who Did They Respond to?Conversation Structure Modeling Using Masked Hierarchical Transformer](https://arxiv.org/pdf/1911.10666.pdf), 25 Nov 2019
29. [From Machine Reading Comprehension to Dialogue State Tracking:Bridging the Gap](https://arxiv.org/pdf/2004.05827.pdf)  13 Apr 2020
30. [Machine Reading Comprehension:The Role of Contextualized Language Modelsand Beyond](https://arxiv.org/pdf/2005.06249.pdf)   13 May 2020
31. [Conversational Machine Comprehension: a Literature Review](https://arxiv.org/pdf/2006.00671.pdf) 1 Jun 2020
32. [GraphFlow: Exploiting Conversation Flow with Graph Neural Networks forConversational Machine Comprehension](https://arxiv.org/pdf/1908.00059.pdf)
33. [Exploiting Text Matching Techniques forKnowledge-Grounded Conversation](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9136717), July 21, 2020.
34. [myquestion](https://ai.stackexchange.com/questions/24547/fine-tune-bert-to-get-contexualized-embedding)
35. [Knowldege-Grounded-Conversation](https://github.com/ChuanMeng/Knowldege-Grounded-Conversation) 

----
# Review

1. [mine](https://docs.google.com/spreadsheets/d/1K897Gt-9NxbkV-uWa_YdX0miB-TLe6SFn0GXY-k6kmo/edit#gid=0) on ale diskrij goog
2. [A Survey on Neural Machine Reading Comprehension](https://arxiv.org/pdf/1906.03824.pdf)  10 Jun 2019
3. [Review Conversational Reading Comprehension](https://arxiv.org/pdf/1902.00821.pdf) 6 Nov 2019
4. [A Survey on Machine Reading Comprehension:Tasks, Evaluation Metrics, and Benchmark Datasets](https://arxiv.org/pdf/2006.11880v1.pdf) , 21 Jun 2020

----
# Datasets
1. [MS MARCO: A Human Generated MAchineReading COmprehension Dataset](http://ceur-ws.org/Vol-1773/CoCoNIPS_2016_paper9.pdf) 2016

---
# Reasoning
1. [Dynamically Fused Graph Network for Multi-hop Reasoning](https://www.aclweb.org/anthology/P19-1617.pdf) August 2, 2019
==============================================================

Historical evolvment
* [ReasoNet: Learning to Stop Reading in Machine Comprehension](https://arxiv.org/pdf/1609.05284.pdf) 20 Jun 2017
* [An Empirical Analysis of Multiple-Turn Reasoning Strategiesin Reading Comprehension Tasks](https://arxiv.org/pdf/1711.03230.pdf) 9 Nov 2017
* [Stochastic Answer Networks for Machine Reading Comprehension](https://arxiv.org/pdf/1712.03556.pdf) 15 May 2018
* [Conversing by Reading:Contentful Neural Conversation with On-demand Machine Reading](https://arxiv.org/pdf/1906.02738.pdf) 7 Jun 2019

